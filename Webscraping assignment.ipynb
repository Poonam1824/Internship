{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Header=[]\n",
    "for i in soup.find_all(\"li\",class_=\"mw-list-item\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Header.append(i)\n",
    "Header\n",
    "import pandas as pd\n",
    "data=pd.DataFrame()\n",
    "data['Headers']=Header\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.imdb.com/chart/top/')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "Movie_title=soup.find_all('td',class_=\"titleColumn\")\n",
    "Movie_title\n",
    "Movies=[]\n",
    "for i in Movie_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Movies.append(i)\n",
    "Movies\n",
    "Movie_rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "Movie_rating\n",
    "Ratings=[]\n",
    "for i in Movie_rating:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Ratings.append(i)\n",
    "Ratings\n",
    "import pandas as pd\n",
    "data=pd.DataFrame()\n",
    "data['Movies name and year of release']=Movies\n",
    "data['Ratings']=Ratings\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c60829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "Movie_title=soup.find_all('td',class_=\"titleColumn\")\n",
    "Movie_title\n",
    "Movies=[]\n",
    "for i in Movie_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Movies.append(i)\n",
    "Movies\n",
    "Ratings=[]\n",
    "for i in Movie_rating:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Ratings.append(i)\n",
    "Ratings\n",
    "import pandas as pd\n",
    "data=pd.DataFrame()\n",
    "data['Movies name and year of release']=Movies\n",
    "data['Ratings']=Ratings\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff736e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page\n",
    "soup=BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "Product_name=soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "Product_name\n",
    "Products=[]\n",
    "for i in Product_name:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Products.append(i)\n",
    "Products\n",
    "Product_price=soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "Product_price\n",
    "Rate=[]\n",
    "for i in Product_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rate.append(i)\n",
    "Rate\n",
    "Product_discount=soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm\")\n",
    "Product_discount\n",
    "\n",
    "Discount=[]\n",
    "for i in Product_discount:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Discount.append(i)\n",
    "Discount\n",
    "import pandas as pd\n",
    "data=pd.DataFrame()\n",
    "data[\"Product Name\"]=Products\n",
    "data[\"Product Price\"]=Rate\n",
    "data[\"Discount\"]=Discount\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521eb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player1=Player[0:10]\n",
    "Player1\n",
    "Team1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team1.append(i)\n",
    "\n",
    "Team2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team2.append(i)\n",
    "Team3=Team2[0:18:2]\n",
    "Team4=Team1+Team3\n",
    "Points1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points1.append(i)\n",
    "\n",
    "Points2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points2.append(i)\n",
    "Points3=Points2[1:19:2]\n",
    "Points4=Points1+Points3\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "\n",
    "Rating1=Rating[0:10]\n",
    "print(len(Player1),len(Team1+Team3),len(Points1+Points3),len(Rating1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player1,'Team':Team4,'Points':Points4,'Rating':Rating1})\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96601d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--team-name\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player1=Player[0:10]\n",
    "Player1\n",
    "Team1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team1.append(i)\n",
    "\n",
    "Team2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team2.append(i)\n",
    "Team3=Team2[0:18:2]\n",
    "Team4=Team1+Team3\n",
    "Points1=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points1.append(i)\n",
    "\n",
    "Points2=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Points2.append(i)\n",
    "Points3=Points2[1:19:2]\n",
    "Points4=Points1+Points3\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "\n",
    "Rating1=Rating[0:10]\n",
    "print(len(Player1),len(Team1+Team3),len(Points1+Points3),len(Rating1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player1,'Team':Team4,'Points':Points4,'Rating':Rating1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Player=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Player.append(i)\n",
    "Player[0:10]\n",
    "\n",
    "Team=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Team.append(i)\n",
    "Team[0:10]\n",
    "\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"): \n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Rating.append(i)\n",
    "Rating[0:10]\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Player,'Team':Team,'Rating':Rating})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://coreyms.com/')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Post_title=soup.find_all('a',class_=\"entry-title-link\")\n",
    "Post_title\n",
    "Title=[]\n",
    "for i in Post_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title1=Title[0:9]\n",
    "Title1\n",
    "Post_date=soup.find_all('time',class_=\"entry-time\")\n",
    "Post_date\n",
    "Date=[]\n",
    "for i in Post_date:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Date.append(i)\n",
    "Date1=Date[0:9]\n",
    "Date1\n",
    "Post_content=soup.find_all('div',class_=\"entry-content\")\n",
    "Post_content\n",
    "Content=[]\n",
    "for i in Post_content:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Content.append(i)\n",
    "Content1=Content[0:9]\n",
    "Content1\n",
    "Link=[]\n",
    "for i in soup.find_all('iframe',class_=\"youtube-player\"):\n",
    "    Link.append(i['src'])\n",
    "Link\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title1,'Date':Date1,'Content':Content1,'Link':Link})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Write a python program to scrape house details from mentioned URL. It should include house title, location, area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar,  Rajaji Nagar.\n",
    "\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIiLCJzaG93TWFwIjpmYWxzZX0seyJsYXQiOjEyLjk3ODM2OTIsImxvbiI6NzcuNjQwODM1NiwicGxhY2VJZCI6IkNoSUprUU4zR0tRV3Jqc1JOaEJRSnJoR0Q3VSIsInBsYWNlTmFtZSI6IkluZGlyYW5hZ2FyIiwic2hvd01hcCI6ZmFsc2V9LHsibGF0IjoxMi45MDczODU5LCJsb24iOjc3LjU5OTM2NjgsInBsYWNlSWQiOiJDaElKLTR1QXNoc1ZyanNSRGNELVlfSEFJQlUiLCJwbGFjZU5hbWUiOiJKYXluYWdhcjNyZCBibG9jayIsInNob3dNYXAiOmZhbHNlfV0=&radius=2.0&city=bangalore&locality=Rajajinagar&type=BHK2')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "House_title=soup.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\")\n",
    "House_title\n",
    "Title=[]\n",
    "for i in House_title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title\n",
    "House_location=soup.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "House_location\n",
    "Location=[]\n",
    "for i in House_location:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Location.append(i)\n",
    "Location\n",
    "House_price=soup.find_all('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\")\n",
    "House_price\n",
    "Price=[]\n",
    "for i in House_price:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Price.append(i)\n",
    "Price\n",
    "House_EMI=soup.find_all('div',class_=\"flex flex-col w-33pe items-center border-r border-r-solid border-card-overview-border-color tp:w-half po:w-full last:border-r-1\")\n",
    "House_EMI\n",
    "EMI=[]\n",
    "for i in House_EMI:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    EMI.append(i)\n",
    "EMI1=EMI[1:10:2]\n",
    "House_area=soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "House_area\n",
    "Area=[]\n",
    "for i in House_area:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Area.append(i)\n",
    "Area1=Area[0:15:3]\n",
    "\n",
    "print(len(Title),len(Location),len(Price),len(EMI1),len(Area1))\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title,'Location':Location,'Price':Price,'EMI':EMI1,'Area':Area1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Write a python program to scrape mentioned details from dineout.co.in :\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.dineout.co.in/pune-restaurants/dineout-pay')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "title=soup.find_all('div',class_=\"restnt-info cursor\")\n",
    "title\n",
    "Title=[]\n",
    "for i in title:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Title.append(i)\n",
    "Title\n",
    "cusine=soup.find_all('span',class_=\"double-line-ellipsis\")\n",
    "cusine\n",
    "Cusine=[]\n",
    "for i in cusine:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Cusine.append(i)\n",
    "Cusine\n",
    "location=soup.find_all('div',class_=\"restnt-loc ellipsis\")\n",
    "location\n",
    "Location=[]\n",
    "for i in location:\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Location.append(i)\n",
    "Location\n",
    "Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-5\"):\n",
    "    Rating.append(i)\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"): \n",
    "    Rating.append(i)\n",
    "Rating\n",
    "Image=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    Image.append(i ['data-src'])\n",
    "Image\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Title':Title,'Cusine':Cusine,'Location':Location,'Rating':Rating,'Image':Image})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts .\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page= requests.get('https://www.bewakoof.com/women-tshirts?ga_q=tshirts')\n",
    "page\n",
    "soup=BeautifulSoup(page.content)\n",
    "print(soup)\n",
    "Name=[]\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Name.append(i)\n",
    "Name\n",
    "Price=[]\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    "    i=i.get_text().replace('\\n',\"\")\n",
    "    i=i.strip(\" \")\n",
    "    Price.append(i)\n",
    "Price\n",
    "Image=[]\n",
    "for i in soup.find_all('img',class_=\"productImgTag\"):\n",
    "    Image.append(i['src'])\n",
    "Image\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'Name':Name,'Price':Price,'Image':Image})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76aed58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba837f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f85a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf58171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253387e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c0052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa40daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991519c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858626ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e577072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac09da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ce3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2506e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb4b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e101346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966da20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59ced2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
